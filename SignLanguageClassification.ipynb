{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjhN12N8ZdNw"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from os import getcwd\n",
        "data_train=pd.read_csv('sign_mnist_train.csv')\n",
        "data_test=pd.read_csv('sign_mnist_test.csv')\n",
        "\n",
        "#data = pd.read_csv('dataset.csv')\n",
        "#data_train, data_test = train_test_split(data, test_size=0.2, random_state=25)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In this section you will have to add another dimension to the data\n",
        "# So, for example, if your array is (10000, 28, 28)\n",
        "# You will need to make it (10000, 28, 28, 1)\n",
        "\n",
        "\n",
        "#training_images = np.expand_dims(training_images, axis=3)\n",
        "#testing_images = np.expand_dims(testing_images, axis=3)\n",
        "\n",
        "training_images = data_train.iloc[:,1:].values\n",
        "training_labels = data_train.iloc[:,0].values\n",
        "\n",
        "testing_images = data_test.iloc[:,1:].values\n",
        "testing_labels = data_test.iloc[:,0].values\n",
        "\n",
        "training_images = training_images.reshape(-1,28,28,1)\n",
        "testing_images = testing_images.reshape(-1,28,28,1)\n",
        "\n",
        "\n",
        "print(training_images.shape)\n",
        "print(training_labels.shape)\n",
        "print(testing_images.shape)\n",
        "print(testing_labels.shape)\n",
        "\n",
        "# Their output should be:\n",
        "# (27455, 28, 28, 1)\n",
        "# (27455,)\n",
        "# (7172, 28, 28, 1)\n",
        "# (7172,)"
      ],
      "metadata": {
        "id": "CzWz6KHHZk6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the first 10 images \n",
        "fig, ax = plt.subplots(2,5) \n",
        "fig.set_size_inches(10, 10)\n",
        "k = 0\n",
        "for i in range(2):\n",
        "    for j in range(5):\n",
        "        ax[i,j].imshow(training_images[k].reshape(28, 28) , cmap = \"gray\")\n",
        "        k += 1\n",
        "    plt.tight_layout()"
      ],
      "metadata": {
        "id": "rPzTEaE5Zlrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an ImageDataGenerator and do Image Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "    rescale=1 / 255\n",
        ")\n",
        "    \n",
        "# Keep These\n",
        "print(training_images.shape)\n",
        "print(testing_images.shape)\n",
        "    \n",
        "# Their output should be:\n",
        "# (27455, 28, 28, 1)\n",
        "# (7172, 28, 28, 1)"
      ],
      "metadata": {
        "id": "XJUwwEh6ZqrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(26, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile Model. \n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the Model\n",
        "history = model.fit_generator(train_datagen.flow(training_images, training_labels, batch_size=32),\n",
        "                              steps_per_epoch=len(training_images) / 32,\n",
        "                              epochs=10,\n",
        "                              validation_data=validation_datagen.flow(testing_images, testing_labels, batch_size=32),\n",
        "                              validation_steps=len(testing_images) / 32)\n",
        "\n",
        "\n",
        "\n",
        "model.evaluate(testing_images, testing_labels, verbose=0)"
      ],
      "metadata": {
        "id": "hPgUigcVZwnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ysSFE2EYZxPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions \n",
        "predictions = model.predict_classes(testing_images)\n",
        "for i in range(len(predictions)):\n",
        "    if(predictions[i] >= 9):\n",
        "        predictions[i] += 1\n",
        "predictions[:5]   \n",
        "\n",
        "#Output\n",
        "#array([ 6,  8, 11, 14, 18])\n",
        "\n",
        "# Precision, recall, f1-score for all the classes\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "classes = [\"Class \" + str(i) for i in range(26) if i != 9]\n",
        "print(classification_report(data_test['label'], predictions, target_names = classes))\n",
        "\n",
        "\n",
        "# Confusion Matrix for the model predictions\n",
        "cm = confusion_matrix(data_test['label'],predictions)\n",
        "\n",
        "plt.figure(figsize=(12,7))\n",
        "g = sns.heatmap(cm, cmap='Reds',annot=True,\n",
        "           fmt='')"
      ],
      "metadata": {
        "id": "REQLHHq2Z3cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qrM8_KI6Z97A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}